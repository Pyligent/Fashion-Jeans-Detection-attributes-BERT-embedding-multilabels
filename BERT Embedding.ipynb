{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT Embedding.ipynb","provenance":[],"authorship_tag":"ABX9TyPL1t9karCLaL67F+dhXiYC"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"Y93GAISR2Aok","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MzhatdmQ2XvK","colab_type":"text"},"source":["## BERT Image Attributes and Product Dicreiption Vector Generator"]},{"cell_type":"markdown","metadata":{"id":"8pkX309S2DuC","colab_type":"text"},"source":["### 1. Loading Pre-Trained BERT\n","\n","- Pre-train model: bert-large-uncased\n","-For 24-layer, 1024-hidden, 16-heads, 340M parameters. Trained on lower-cased English text."]},{"cell_type":"code","metadata":{"id":"obeZ2RMl2VcR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":394},"outputId":"74f3a2ad-c5aa-406b-9f39-dbee242a307d","executionInfo":{"status":"ok","timestamp":1585847208083,"user_tz":240,"elapsed":4309,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["!pip install pytorch-pretrained-bert"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pytorch-pretrained-bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\r\u001b[K     |██▋                             | 10kB 20.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 6.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 5.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 5.0MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.12.31)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.18.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n","Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.38.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.15.31)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.5)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->pytorch-pretrained-bert) (2.8.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->pytorch-pretrained-bert) (0.15.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.16.0,>=1.15.31->boto3->pytorch-pretrained-bert) (1.12.0)\n","Installing collected packages: pytorch-pretrained-bert\n","Successfully installed pytorch-pretrained-bert-0.6.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-JkmvMQL5rfq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"outputId":"8acda2cf-152d-4418-9a21-4a8dab9f1643","executionInfo":{"status":"ok","timestamp":1585847948082,"user_tz":240,"elapsed":35959,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["from fastai.vision import *\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aNU9LtFr2-cO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"42096477-81cb-47de-a4ff-fccb9804be78","executionInfo":{"status":"ok","timestamp":1585847245068,"user_tz":240,"elapsed":3309,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["import torch\n","from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n","\n","# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n","import logging\n","#logging.basicConfig(level=logging.INFO)\n","\n","import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["100%|██████████| 231508/231508 [00:00<00:00, 1247007.65B/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ifiEzUtB3IvN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JKVTbJMr56ik","colab_type":"text"},"source":["### Load Atrributes and product Description"]},{"cell_type":"code","metadata":{"id":"72Oec2jW6Ats","colab_type":"code","colab":{}},"source":["path = Path('/content/drive/My Drive/Levis')\n","path_modal = path /'multimodal-search'\n","levis_attri_desc = pd.read_csv(path_modal/'levis_img_attr_label_desc.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qOC_dJWF6O0Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"outputId":"5c929343-16aa-4f4d-d4ba-7692ee39166d","executionInfo":{"status":"ok","timestamp":1585848062042,"user_tz":240,"elapsed":406,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["levis_attri_desc.head()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>description</th>\n","      <th>label</th>\n","      <th>file_path</th>\n","      <th>all_attributes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>exact reproduction of 1961 551z   customized...</td>\n","      <td>551 z customized men's jeans</td>\n","      <td>downloaded_images/748790000___748790000-back-p...</td>\n","      <td>straight,zip,slim fit,medium wash,freewheelin ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>exact reproduction of 1961 551z   customized...</td>\n","      <td>551 z customized men's jeans</td>\n","      <td>downloaded_images/748790000___748790000-side-p...</td>\n","      <td>straight,zip,slim fit,medium wash,freewheelin ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>exact reproduction of 1961 551z   customized...</td>\n","      <td>551 z customized men's jeans</td>\n","      <td>downloaded_images/748790000___748790000-alt6-p...</td>\n","      <td>straight,zip,slim fit,medium wash,freewheelin ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>exact reproduction of 1961 551z   customized...</td>\n","      <td>551 z customized men's jeans</td>\n","      <td>downloaded_images/748790000___748790000-front-...</td>\n","      <td>straight,zip,slim fit,medium wash,freewheelin ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>perfect fit for athletic builds    relaxed...</td>\n","      <td>541  athletic taper fit camo patch men's jeans</td>\n","      <td>downloaded_images/181810426___181810426-front-...</td>\n","      <td>athletic,taper,relaxed,541 ,zip,sits at waist,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         description  ...                                     all_attributes\n","0    exact reproduction of 1961 551z   customized...  ...  straight,zip,slim fit,medium wash,freewheelin ...\n","1    exact reproduction of 1961 551z   customized...  ...  straight,zip,slim fit,medium wash,freewheelin ...\n","2    exact reproduction of 1961 551z   customized...  ...  straight,zip,slim fit,medium wash,freewheelin ...\n","3    exact reproduction of 1961 551z   customized...  ...  straight,zip,slim fit,medium wash,freewheelin ...\n","4      perfect fit for athletic builds    relaxed...  ...  athletic,taper,relaxed,541 ,zip,sits at waist,...\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"LLOobcwm64-M","colab_type":"text"},"source":["### Input "]},{"cell_type":"code","metadata":{"id":"x00UnY216Q6B","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5140ca52-f68f-44c5-b22c-089eae2b2e98","executionInfo":{"status":"ok","timestamp":1585848128553,"user_tz":240,"elapsed":305,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["attr_text = levis_attri_desc['all_attributes'][0]\n","attr_text"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"straight,zip,slim fit,medium wash,freewheelin suze , medium wash,men's regular,non stretch,100% cotton,non,stretch denim,imported\""]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"2wR8UUYt6hKY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"eb22c8bc-be9c-494a-c8a5-6c397d1289da","executionInfo":{"status":"ok","timestamp":1585848172670,"user_tz":240,"elapsed":542,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["attr_text_clean = attr_text.replace(',',' ')\n","attr_text_clean"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"straight zip slim fit medium wash freewheelin suze   medium wash men's regular non stretch 100% cotton non stretch denim imported\""]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"BVseXIOj6r4V","colab_type":"code","colab":{}},"source":["marked_text = \"[CLS] \" + attr_text_clean + \" [SEP]\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s4fdi6iZ6vNl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":493},"outputId":"6c720984-5500-4a4f-a3a1-58f11dda327a","executionInfo":{"status":"ok","timestamp":1585848260115,"user_tz":240,"elapsed":366,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["# Split the sentence into tokens.\n","tokenized_text = tokenizer.tokenize(marked_text)\n","\n","# Map the token strings to their vocabulary indeces.\n","indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","\n","# Display the words with their indeces.\n","for tup in zip(tokenized_text, indexed_tokens):\n","    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[CLS]           101\n","straight      3,442\n","zip          14,101\n","slim         11,754\n","fit           4,906\n","medium        5,396\n","wash          9,378\n","free          2,489\n","##wheel      22,920\n","##in          2,378\n","su           10,514\n","##ze          4,371\n","medium        5,396\n","wash          9,378\n","men           2,273\n","'             1,005\n","s             1,055\n","regular       3,180\n","non           2,512\n","stretch       7,683\n","100           2,531\n","%             1,003\n","cotton        6,557\n","non           2,512\n","stretch       7,683\n","denim        26,762\n","imported     10,964\n","[SEP]           102\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-BQ8tJBt68aj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"937f5606-e3c5-4c1e-eab5-13fe5fec2c7c","executionInfo":{"status":"ok","timestamp":1585848282754,"user_tz":240,"elapsed":410,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["# Mark each of tokens as belonging to sentence \"1\".\n","segments_ids = [1] * len(tokenized_text)\n","\n","print (segments_ids)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ao7CI2CK7Gya","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DlkLFEEe7NSp","colab_type":"text"},"source":["### Extract Embeddings"]},{"cell_type":"code","metadata":{"id":"2u4ONTZ37VUQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d5359597-5468-4fea-827f-d8742dc0a910","executionInfo":{"status":"ok","timestamp":1585848426950,"user_tz":240,"elapsed":66644,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["# Convert inputs to PyTorch tensors\n","tokens_tensor = torch.tensor([indexed_tokens])\n","segments_tensors = torch.tensor([segments_ids])\n","\n","# Load pre-trained model (weights)\n","# model = BertModel.from_pretrained('bert-base-uncased')\n","model = BertModel.from_pretrained('bert-large-uncased')\n","\n","# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n","model.eval()"],"execution_count":13,"outputs":[{"output_type":"stream","text":["100%|██████████| 1248501532/1248501532 [00:31<00:00, 39480260.33B/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n","    (position_embeddings): Embedding(512, 1024)\n","    (token_type_embeddings): Embedding(2, 1024)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (12): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (13): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (14): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (15): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (16): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (17): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (18): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (19): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (20): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (21): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (22): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (23): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=1024, out_features=1024, bias=True)\n","            (key): Linear(in_features=1024, out_features=1024, bias=True)\n","            (value): Linear(in_features=1024, out_features=1024, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"95vk3OXG7Z0v","colab_type":"code","colab":{}},"source":["# Predict hidden states features for each layer\n","with torch.no_grad():\n","    encoded_layers, _ = model(tokens_tensor, segments_tensors)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y2eUq5LU7sX1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"3c7fa6c5-871f-45ea-8095-cfaced620c7e","executionInfo":{"status":"ok","timestamp":1585848523494,"user_tz":240,"elapsed":410,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["print (\"Number of layers:\", len(encoded_layers))\n","layer_i = 0\n","\n","print (\"Number of batches:\", len(encoded_layers[layer_i]))\n","batch_i = 0\n","\n","print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n","token_i = 0\n","\n","print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Number of layers: 24\n","Number of batches: 1\n","Number of tokens: 28\n","Number of hidden units: 1024\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q2gvhzRH8Bj5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"565c765d-222c-4ede-cd77-e0b440bd4406","executionInfo":{"status":"ok","timestamp":1585848572398,"user_tz":240,"elapsed":384,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["# Concatenate the tensors for all layers. \n","token_embeddings = torch.stack(encoded_layers, dim=0)\n","\n","token_embeddings.size()"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([24, 1, 28, 1024])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"oXZR_SJm8Ngg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a5c11c6b-d9cd-43dd-95f8-97911e55e365","executionInfo":{"status":"ok","timestamp":1585848607213,"user_tz":240,"elapsed":380,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["# Remove dimension 1, the \"batches\".\n","token_embeddings = torch.squeeze(token_embeddings, dim=1)\n","\n","token_embeddings.size()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([24, 28, 1024])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"94XJ4L6L8WAn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"bf3eefcc-039e-4c70-e011-80d90c3885c2","executionInfo":{"status":"ok","timestamp":1585848627715,"user_tz":240,"elapsed":513,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["# Swap dimensions 0 and 1.\n","token_embeddings = token_embeddings.permute(1,0,2)\n","\n","token_embeddings.size()"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([28, 24, 1024])"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"vnRspkuM8a-2","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8FVXuccz8dW7","colab_type":"text"},"source":["### Creating word and sentence vectors\n","\n","#### 1. Word Vectors\n","\n","\n","- Concatenate the vectors (that is, append them together) from the last four layers.\n","    "]},{"cell_type":"markdown","metadata":{"id":"j4H_Nq2Y-A5m","colab_type":"text"},"source":["- Word vector(concatenate)"]},{"cell_type":"code","metadata":{"id":"UQ32JCoH8gr1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"de12f7cb-dc4e-4c8c-acb7-7508335c716c","executionInfo":{"status":"ok","timestamp":1585848957375,"user_tz":240,"elapsed":425,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["token_vecs_cat = []\n","\n","# `token_embeddings` is a [22 x 12 x 768] tensor.\n","\n","# For each token in the sentence...\n","for token in token_embeddings:\n","    \n","    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n","    \n","    # Use `cat_vec` to represent `token`.\n","    token_vecs_cat.append(cat_vec)\n","\n","print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Shape is: 28 x 4096\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FiJScFz_9rfD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jUcGb6tQ-GbJ","colab_type":"text"},"source":["- Word vector(summing)"]},{"cell_type":"code","metadata":{"id":"QysFUobj-Vcc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4febeb5e-932a-4be4-89a3-e840e15a574a","executionInfo":{"status":"ok","timestamp":1585849167078,"user_tz":240,"elapsed":406,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["token_vecs_sum = []\n","\n","for token in token_embeddings:\n","    # Sum the vectors from the last four layers.\n","    sum_vec = torch.sum(token[-4:], dim=0)\n","    \n","    # Use `sum_vec` to represent `token`.\n","    token_vecs_sum.append(sum_vec)\n","\n","print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Shape is: 28 x 1024\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"X7HfawoM-ers","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"68EEVxz_-iDj","colab_type":"text"},"source":["#### 2. Sentence Vector"]},{"cell_type":"code","metadata":{"id":"Mp1dtKEZ-qSb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"6ba4a430-025a-409f-d3d0-6a1a270154c9","executionInfo":{"status":"ok","timestamp":1585849271252,"user_tz":240,"elapsed":363,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["token_vecs = encoded_layers[23][0]\n","\n","sentence_embedding = torch.mean(token_vecs, dim=0)\n","print (\"The sentence embedding vector of shape:\", sentence_embedding.size())"],"execution_count":21,"outputs":[{"output_type":"stream","text":["The sentence embedding vector of shape: torch.Size([1024])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0hAgNJ7C-4IX","colab_type":"code","colab":{}},"source":["def bert_sentence_embedding(attr_text,model):\n","\n","  marked_text = \"[CLS] \" + attr_text + \" [SEP]\"\n","  # Add the special tokens.\n","  marked_text = \"[CLS] \" + attr_text + \" [SEP]\"\n","\n","  # Split the sentence into tokens.\n","  tokenized_text = tokenizer.tokenize(marked_text)\n","\n","  # Map the token strings to their vocabulary indeces.\n","  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n","\n","  segments_ids = [1] * len(tokenized_text)\n","\n","  # Convert inputs to PyTorch tensors\n","  tokens_tensor = torch.tensor([indexed_tokens])\n","  segments_tensors = torch.tensor([segments_ids])\n","  \n","  # Predict hidden states features for each layer\n","  with torch.no_grad():\n","    encoded_layers, _ = model(tokens_tensor, segments_tensors)\n","\n","  token_vecs = encoded_layers[23][0]\n","\n","  sentence_embedding = torch.mean(token_vecs, dim=0)\n","  #print (\"The sentence embedding vector of shape:\", sentence_embedding.size())  \n","\n","  return sentence_embedding\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fa8WmhkdB-CW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1ff44a90-6ada-44dc-aa15-c8231395dd32","executionInfo":{"status":"ok","timestamp":1585851894048,"user_tz":240,"elapsed":503,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["p0_str = levis_attri_desc['all_attributes'][0].replace(',',' ')\n","\n","p0_str"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"straight zip slim fit medium wash freewheelin suze   medium wash men's regular non stretch 100% cotton non stretch denim imported\""]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"3L43vJHyCbqv","colab_type":"code","colab":{}},"source":["product_1_emb = bert_sentence_embedding(levis_attri_desc['all_attributes'][1].replace(',',' '),model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i4NvNywGCiUx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cc3f1aca-79e2-4d3f-b60a-1d477b366aa6","executionInfo":{"status":"ok","timestamp":1585851905499,"user_tz":240,"elapsed":637,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["print (\"The sentence embedding vector of shape:\", product_1_emb.size()) "],"execution_count":55,"outputs":[{"output_type":"stream","text":["The sentence embedding vector of shape: torch.Size([1024])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QUY6snDjCnKn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"3014a46c-0a31-4d86-ca60-0b41db3cd1e6","executionInfo":{"status":"ok","timestamp":1585851912512,"user_tz":240,"elapsed":469,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["product_1_emb"],"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.2340,  0.2931,  0.3560,  ..., -0.5918, -0.0954, -0.0612])"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"FbYYw-GzCs2v","colab_type":"code","colab":{}},"source":["product_2_emb = bert_sentence_embedding(levis_attri_desc['all_attributes'][7].replace(',',' '),model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wntGAID6C32-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"db41ecf4-9a4f-478a-da30-64924e6eaf74","executionInfo":{"status":"ok","timestamp":1585851920115,"user_tz":240,"elapsed":529,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["product_2_emb"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.1943,  0.0131,  0.0813,  ..., -0.2270, -0.0765, -0.0145])"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"5AqkJzCSGLXi","colab_type":"code","colab":{}},"source":["product_0_emb = bert_sentence_embedding(levis_attri_desc['all_attributes'][0].replace(',',' '),model)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KqZrt_kbC5e1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NCVtDZUMGduW","colab_type":"code","colab":{}},"source":["from scipy.spatial.distance import cosine\n","\n","diff_product_0_1 =  cosine(product_0_emb, product_1_emb)\n","\n","diff_product_0_2 =  cosine(product_0_emb, product_2_emb)\n","\n","\n","if diff_product_0_1 > diff_product_0_2:\n","  print('product 0 is more similar to product 1 then product 2')\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ur6qSwbuGoti","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"83d99d48-2849-4e05-9b0f-4e659cd01183","executionInfo":{"status":"ok","timestamp":1585852412432,"user_tz":240,"elapsed":377,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["diff = product_0_emb - product_1_emb\n","print(cosine(product_0_emb, product_1_emb))"],"execution_count":72,"outputs":[{"output_type":"stream","text":["0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7Plm-At8Hldj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"a52597c2-0085-469c-9adb-f2a79b47a375","executionInfo":{"status":"ok","timestamp":1585852273912,"user_tz":240,"elapsed":361,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["product_1_emb"],"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-0.2340,  0.2931,  0.3560,  ..., -0.5918, -0.0954, -0.0612])"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"Nr0LnGKxHn2i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"c64bae3a-3626-4b29-99e5-f699851280e2","executionInfo":{"status":"ok","timestamp":1585852005440,"user_tz":240,"elapsed":434,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["levis_attri_desc['all_attributes'][1]"],"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"straight,zip,slim fit,medium wash,freewheelin suze , medium wash,men's regular,non stretch,100% cotton,non,stretch denim,imported\""]},"metadata":{"tags":[]},"execution_count":63}]},{"cell_type":"code","metadata":{"id":"HspjTm7nJToi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"29a5fdc2-162a-4dc0-a6a3-8d99a322d352","executionInfo":{"status":"ok","timestamp":1585852013633,"user_tz":240,"elapsed":294,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["levis_attri_desc['all_attributes'][0]"],"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"straight,zip,slim fit,medium wash,freewheelin suze , medium wash,men's regular,non stretch,100% cotton,non,stretch denim,imported\""]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"lcEIibFmJVrJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"9f010c78-4e6a-4e3c-9403-704016a0c1c6","executionInfo":{"status":"ok","timestamp":1585852026095,"user_tz":240,"elapsed":391,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["levis_attri_desc['all_attributes'][7]"],"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'straight,550 ,zip,sits at waist,relaxed through hip and thigh,slightly tapered leg opening: 19.5\",range , black,men\\'s big & tall,non stretch,100% cotton,non,stretch denim,zip fly,5,pocket,wash and dry inside out with like colors, liquid detergent is recommended,imported'"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"uLfZwITzJYsa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"27a5b600-b4fd-47d9-e82d-2ae9353c4f24","executionInfo":{"status":"ok","timestamp":1585852490935,"user_tz":240,"elapsed":350,"user":{"displayName":"Tao Jin","photoUrl":"","userId":"05811861299079065602"}}},"source":["cosine([1, 0, 0], [1,0, 0])"],"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.0"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"id":"wk5QmEBILIVs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}